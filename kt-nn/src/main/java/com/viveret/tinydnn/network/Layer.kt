package com.viveret.tinydnn.network

import android.graphics.Canvas
import com.viveret.tinydnn.basis.Index3D
import com.viveret.tinydnn.basis.Tensor
import com.viveret.tinydnn.basis.Vect
import com.viveret.tinydnn.basis.vector_type
import com.viveret.tinydnn.data.graphics.LayerVizualization
import com.viveret.tinydnn.optimizer.Optimizer
import java.io.InputStream
import java.io.OutputStream

interface Layer<edgeptr_t> : Node {
    val color: Int
    fun set_parallelize(parallelize: Boolean)

    fun parallelize(): Boolean

    ///< number of incoming edges in this layer
    fun in_channels(): Long

    ///< number of outgoing edges in this layer
    fun out_channels(): Long

    fun in_data_size(): Long

    fun out_data_size(): Long

    fun in_data_shape(): List<Index3D>

    fun out_data_shape(): List<Index3D>

    fun weights(): List<Vect>

    fun weights_grads(): List<Tensor>

    fun inputs(): List<edgeptr_t>

    fun outputs(): List<edgeptr_t>

    fun set_out_grads(grad: List<Vect>, cnt: Long)

    fun set_in_data(data: List<Vect>, cnt: Long)

    fun output(out: List<Tensor>)

    fun in_types(): List<vector_type>

    fun out_types(): List<vector_type>

    fun set_trainable(trainable: Boolean)

    fun trainable(): Boolean

    /**
     * array of input shapes (width x height x depth)
     */
    fun in_shape(): List<Index3D>

    /**
     * array of output shapes (width x height x depth)
     */
    fun out_shape(): List<Index3D>

    /**
     * name of layer, should be unique for each concrete class
     */
    fun layer_type(): String

    /**
     * number of incoming connections for each output unit
     * used only for weight/bias initialization methods which require fan-in
     * elementCount
     * (e.g. xavier)
     * override if the layer has trainable Weights, and scale of initialization
     * is
     * important
     */
    fun fan_in_size(): Long

    /**
     * number of outgoing connections for each input unit
     * used only for weight/bias initialization methods which require fan-out
     * elementCount
     * (e.g. xavier)
     * override if the layer has trainable Weights, and scale of initialization
     * is
     * important
     */
    fun fan_out_size(): Long


    fun weight_init(f: Vect): Layer<*>

    fun bias_init(f: Vect): Layer<*>

    fun save(
            os: OutputStream,
            precision: Int// = std::numeric_limits<Float>::digits10 + 2
            /*by default, we want there to be enough precision*/)


    fun load(
            `is`: InputStream,
            precision: Int// = std::numeric_limits<Float>::digits10 + 2
            /*by default, we want there to be enough precision*/)


    fun load(src: List<Float>, idx: Int)

    /**
     * @param in_data  input vectors of this layer (data, weight, bias)
     * @param out_data output vectors
     */
    fun forward_propagation(in_data: List<Tensor>, out_data: List<Tensor>)

    /**
     * return delta of previous layer (delta=\frac{dE}{da}, a=wx in
     * fully-connected layer)
     * @param in_data  input vectors (Fill vectors as forward_propagation)
     * @param out_data output vectors (Fill vectors as forward_propagation)
     * @param out_grad gradient of output vectors (i-th vector correspond with
     * out_data[i])
     * @param in_grad  gradient of input vectors (i-th vector correspond with
     * in_data[i])
     */
    fun back_propagation(in_data: List<Tensor>,
                         out_data: List<Tensor>,
                         out_grad: List<Tensor>,
                         in_grad: List<Tensor>)

    /** @brief Allocates data in the computational graph and reset Weights if
     * it's needed or the data is not already initialized.
     *
     * @param reset_weight Boolean value to force to reset the Weights.
     * Weights will be automatically reset if the are not initialized.
     */
    fun setup(reset_weight: Boolean)

    /** @brief Initializes the vectors containing the trainable data.
     *
     * In case that a layer/node is set to be not trainable, it does
     * nothing and returns a void. Otherwise, for each input connection
     * and depending of the data nature (weight or bias) calls their
     * pertinent initialization function and fill the vectors with the
     * data generated by the mentioned functions.
     */
    fun init_weight()


    fun clear_grads()

    fun update_weight(o: Optimizer)

    fun set_sample_count(sample_count: Long)

    fun draw(canvas: Canvas, position: Int)

    fun getVisualizations(): List<LayerVizualization>
}
